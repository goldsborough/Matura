% Probability

\input{preamble.tex}

\begin{document}
\thispagestyle{plain}

\heading{Wahrscheinlichkeit}

Die Wahrscheinlichkeitsrechnung umfasst die Untersuchung und Beschreibung von Zufallsexperimenten sowie -ereignissen. Bei der Diskussion der Wahrscheinlichkeitsrechnung sind vor allem Begriffe wie \emph{Zufallsereignis}, \emph{Zufallsvariable}, \emph{Ereignismenge}, \emph{Erwartungswert} oder \emph{Standardabweichung} wichtig. Ein ebenso essentieller Bestandteil der Wahrscheinlichkeitsrechnung ist die Kombinatorik, durch welche sich Kombinationen und Permutationen von Ereignissen ermitteln lassen. Unter bestimmten Bedingungen wird die Modellierung eines Zufallsexperiment durch die \emph{Binomialverteilung} m\"{o}glich, welchem ein \emph{Bernoulli-Experiment} zu Grunde liegt. 

\sub{Zufallsexperimente}

Ein Zufallsexperiment wie das Werfen einer M\"{u}nze oder eines W\"{u}rfels ist ein Prozess, dessen Resultat so irregul\"{a}r ist, dass es nicht definitiv vorhergesagt werden kann. Dennoch hat dieses Zufallsexperiment, sofern es diskret ist, einen bestimmten Ergebnisraum. Dieser Ergebnisraum wird \emph{Ergebnismenge} $\Omega$ genannt und umfasst alle m\"{o}glichen Ergebnisse des Zufallsversuchs. Ein einzelnes Element der Ergebnismenge $\Omega$ wird dabei als \emph{Elementarereignis} $\omega$ bezeichnet. Ein Ereignis $A$ ist eine Teilmenge der Ergebnismenge $\Omega$. F\"{u}r jedes Ereignis $A$ existiert au\ss{}erdem ein logisches \emph{Gegenereignis} $A'$. Dieses umfasst alle Elementarereignisse der Ergebnismenge, au\ss{}er jene des Ereignisses $A$. 

\textbf{Ergebnismenge $\Omega$} \defas Alle bei einem Zufallsversuch m\"{o}glichen Ergebnisse: $\Omega = \{ \omega_1, \omega_2, ..., \omega_n\}$

\textbf{Elementarereignis} \defas Ein Element der Ergebnismenge: $\omega \in \Omega$

\textbf{Ereignis $A$} \defas Eine bestimmte Teilmenge der Ergebnismenge: $A \subseteq \Omega$

\textbf{Gegenereignis $A'$} \defas Die Menge aller $\omega$, die bei einem Ereignis nicht auftreten: $A' = \Omega \setminus A$

\sub{Wahrscheinlichkeit von Ereignissen}

Die \emph{theoretische} Wahrscheinlichkeit eines Zufallsereignisses ist ihr relativer Anteil an der Ergebnismenge. Beispielsweise ist die theoretische Wahrscheinlichkeit, eine beliebige Zahl zu w\"{u}rfeln, jeweils $1 \div 6 = 0.1\dot{6}$. Dies folgt daraus, dass der relative Anteil des Ereignises $A$, welches eine beliebige Zahl umfasst, genau ein Sechstel der Ergebnismenge $\Omega$ ausmacht, welche sechs Zahlen umfasst. F\"{u}hrt man ein solches Zufallsexperiment durch, wird man jedoch merken, dass die relative H\"{a}ufigkeit eines Ereignisses bei einer kleinen Versuchsserie stark von der theoretischen Wahrscheinlichkeit abweicht. Beispielsweise ist es meistens nicht der Fall, dass bei sechs W\"{u}rfen eines W\"{u}rfels jede Zahl genau einmal vorkommt. Erst bei einer gro\ss{}en Anzahl an Durchf\"{u}hrungen n\"{a}hert sich die relative H\"{a}ufigkeit eines Ereignisses seiner theoretischen Wahrscheinlichkeit. So mag nach sechs W\"{u}rfen eines W\"{u}rfels die relative H\"{a}ufigkeit jeder Zahl meist stark von den theoretisch erwarteten $\sim 16.67$ Prozent abweichen, so wird sie sich jedoch nach einer sehr langen Versuchsreihe --- einer Million W\"{u}rfe --- stark an die theoretische Wahrscheinlichkeit n\"{a}hren. Dieses Ph\"{a}nomen nennt sich das \zitat{empirische Gesetz der gro\ss{}en Zahlen}.

\pagebreak

\textbf{Theoretische Wahrscheinlichkeit} \defas der relative Anteil eines Ereignisses an der Ergebnismenge

\textbf{Empirische Wahrscheinlichkeit} \defas die H\"{a}ufigkeit eines Zufallsreignisses relativ zur Versuchsserie

Die Theoretische Wahrscheinlchkeit ist also der Grenzwert der relativen H\"{a}ufigkeit bzw. der empirischen Wahrscheinlichkeit bei einer unendlich langen Versuchsserie: $$\text{Theoretische Wahrscheinlichkeit} = \lim_{n \rightarrow \infty} \frac{\text{H\"{a}ufigkeit eines Ereignisses}}{\text{L\"{a}nge der Verssuchserie } n}$$

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}
		\begin{axis}
		[
			width=15cm,
			height=6.5cm,
			xlabel = {L\"{a}nge der Versuchsserie},
			ylabel = {Relative H\"{a}ufigkeit},
			axis lines = left,
			grid = major
		]

		\addplot [teal] table [mark=none, x=n, y=p] {data/p10.dat};

		\addlegendentry{10 W\"{u}rfe};

		\end{axis}
	\end{tikzpicture}
	%
	\vspace{0.3cm}
	%
	\begin{tikzpicture}
		\begin{axis}
		[
			width=15cm,
			height=6.5cm,
			xlabel = {L\"{a}nge der Versuchsserie},
			ylabel = {Relative H\"{a}ufigkeit},
			axis lines = left,
			grid=major,
			scaled y ticks=false,
			yticklabel style={/pgf/number format/fixed},
			ytick={0.1, 0.12, ..., 0.167},
			legend pos = south east
		]

		\addplot [red] table [mark=none, x=n, y=p] {data/p1000.dat};

		\addlegendentry{1000 W\"{u}rfe};

		\end{axis}
	\end{tikzpicture}
	%
	\vspace{0.3cm}
	%
	\begin{tikzpicture}
		\begin{axis}
		[
			width=15cm,
			height=6.5cm,
			xlabel = {L\"{a}nge der Versuchsserie},
			ylabel = {Relative H\"{a}ufigkeit},
			axis lines = left,
			grid=major,
			xtick={200000,400000,600000,800000,1000000},
			xticklabel style={/pgf/number format/fixed},
			scaled x ticks=false,
			ytick={0.165, 0.166, ..., 0.17},
			yticklabel style={/pgf/number format/precision=4},
			legend pos = south east
		]

		\addplot [blue] table [mark=none, x=n, y=p] {data/p1000000.dat};

		\addlegendentry{1000000 W\"{u}rfe};

		\end{axis}
	\end{tikzpicture}
\end{figure}

\pagebreak

Noch einige Definitionen:

\begin{itemize}
	\item Jedes Elementarereignis $\omega$ sowie jedes Ereignis $A$ besitzen eine Wahrscheinlichkeit zwischen null und eins: $0 \leq P(A) \leq 1 \,\,\forall\,\, A \subseteq \Omega$

	\item Die Wahrscheinlichkeit eines Ereignisses, welches nicht Teilmenge der Ergebnismenge $\Omega$ ist, betr\"{a}gt stets null: $P(A) = 0 \,\,\forall\,\, A \nsubseteq \Omega$

	\item Ebenso ist die Wahrscheinlichkeit, dass kein Ereignis eintritt, gleich null: $P(\varnothing) = 0$

	\item Die Wahrscheinlichkeit, dass irgendein beliebiges Ereignis eintritt ist gleich eins: $P(\Omega) = 1$

	\item Die Wahrscheinlichkeit eines Gegenereignisses $A'$ ist gleich der Gegenwahrscheinlichkeit des Ereignisses $A$: $P(A') = 1 - P(A)$
\end{itemize}

\sub{Kombinatorik}

In vielen F\"{a}llen gibt mehrere M\"{o}glichkeiten, aus der Ergebnismenge $\Omega$ das selbe Ereignis $A \subseteq \Omega$ zu bilden. Ist beispielsweise die Reihenfolge der Elemente des Ereignisses $A = \{\omega_1, \omega_2, \omega_3\}$ egal, so gibt es $3 \cdot 2 \cdot 1 = 6$ M\"{o}glichkeiten, die Reihenfolge zu ver\"{a}ndern, in der die Elementarereignisse auftreten. Diese M\"{o}glichkeiten werden \emph{Permutationen} genannt. Die Untersuchung der Permutationen eines Zufallsversuchs ist ein Teilgebiet der Kombinatorik, welche sich ebenso mit den \emph{Variationen} sowie \emph{Kombinationen} von Ereignissen besch\"{a}ftigt.

Allgemein sei gesagt, dass die gesamte Anzahl an M\"{o}glichkeiten eines $k$-stufigen kombinatorischen Versuchs gleich dem Produkt der M\"{o}glichkeiten jeder Stufe ist. Dies nennt sich die \emph{Produktregel der Kombinatorik}. Gibt es beispielsweise in der ersten Stufe eines Zufallsversuchs f\"{u}nf M\"{o}glichkeiten, ein f\"{u}r das Ereignis $A$ g\"{u}nstiges Elementarereignis auszuw\"{a}hlen, in der zweite Stufe vier M\"{o}glichkeiten und in der dritten drei M\"{o}glichkeiten, so ist die Gesamtanzahl an M\"{o}glichkeiten gleich $5 \cdot 4 \cdot 3 = 60$.

\subsub{Permutationen}

Die Anzahl an Permutationen einer Menge von Ereignissen oder Objekten beschreibt die Anzahl an M\"{o}glichkeiten, diese Objekte in einer bestimmten Reihenfolge und ohne Wiederholung anzuordnen. Dabei muss jedes Objekt der Menge pro Anordnung genau einmal ausgew\"{a}hlt werden. Die Anzahl an Permutationen von $n$ Objekten l\"{a}sst durch ihre Fakult\"{a}t $n!$ beschreiben. Der Ausdruck $n!$ ist dabei equivalent zur folgenden Produktserie: $$n \cdot (n - 1) \cdot (n - 2) \cdot ... \cdot 1 = \prod_{k=0}^{n - 1} n - k$$ Es l\"{a}sst sich also festhalten: $$n! \, \defas \text{Anzahl an Permutationen von $n$ Objekten ohne Wiederholung}$$

\beispiel{Wie viele M\"{o}glichkeiten gibt es, 3 \"{A}pfel, 5 Menschen und 8 Kartoffeln zu essen, wenn man jedes Objekt einer Nahrungsform aufgegessen haben muss, bevor man eine neue Nahrungsform zu verspeisen beginnt?}

Man beginnt bei den \"{A}pfeln. F\"{u}r diese gibt es zuerst drei M\"{o}glichkeiten, einen Apfel zu essen. Danach ist es einer weniger, also gibt es in der zweiten Stufe des Versuchs nur mehr zwei M\"{o}glichkeiten, einen Apfel zu essen. Ist der Zweite gegessen, bleibt nur mehr eine einzige M\"{o}glichkeit, einen Apfel zu essen, da es nur mehr einen gibt. Somit ist die Anzahl an Permutationen f\"{u}r die \"{A}pfel gleich $3! = 3 \cdot 2 \cdot 1 = 6$. Das selbe Verfahren f\"{u}hrt zu $5! = 120$ Permutationen f\"{u}r die Menge der Menschen und $8! = 40320$ f\"{u}r die Menge der Kartoffeln. Da alle Objekte einer Nahrungsform gegessen werden m\"{u}ssen, bevor eine neue begonnen wird (z.B. zuerst Menschen, dann Kartoffeln, dann \"{A}pfel), gibt es nochmals $3! = 6$ M\"{o}glichkeiten, die einzelnen \zitat{Bl\"{o}cke} anzureihen. Insgesamt gibt es also: $$(3! \cdot 5! \cdot 8!) \cdot 3! = 174\,182\,400 \text{ M\"{o}glichkeiten}$$

Untersucht man hingegen die Anzahl an Permutationen mit Wiederholung von Objekten, so kann jedes der $n$ Objekte $n$ mal vorkommen: $$n^n \defas \text{Anzahl an Permutationen von $n$ Objekten mit Wiederholung}$$

\subsub{Variationen}

Die Anzahl an Variationen $(n)_k$ von $k$ aus $n$ Objekten beschreibt die Anzahl an M\"{o}glichkeiten, aus den $n$ Objekten $k$ in einer bestimmten Reihenfolge auszuw\"{a}hlen. Dabei darf keines der $k$ Objekte doppelt gew\"{a}hlt werden. Man \"{u}berlege sich, dass es zuerst $n$ M\"{o}glichkeiten gibt, dann $n-1$, dann $n-2$ usw. bis $n-k$. Gilt $k = n$, so ist dies equivalent zur Fakult\"{a}t von $n$ und somit zur Berechnung der Permutationen einer Menge von Objekten. Die Berechnung der Variationen einer Menge von Objekten ist also gewisserma\ss{}en eine verk\"{u}rzte Form der Berechnung ihrer Permutationen. Ebenso kann eine Permutation als eine Sonderform einer Variation gesehen werden, f\"{u}r die gilt $k = n$. Allgemein sei also definiert: $$(n)_k = \prod_{i=0}^{k-1} n - i \defas \text{Anzahl an Variationen von $k$ aus $n$ Objekten, ohne Wiederholung.} $$

\beispiel{Wie viele M\"{o}glichkeiten gibt es, aus 32 Sportmannschaften bei einem Turnier einen Erst-, einen Zweit- und einen Drittplatzierten zu finden?}

F\"{u}r den ersten Platz gibt es 32 m\"{o}gliche Teams. Ist ein Sieger gefunden, verbleiben 31 Mannschaften f\"{u}r den zweiten Platz. Somit gibt es letztlich 30 M\"{o}glichkeiten, den Drittplatzierten zu bestimmen. Insgesamt gibt es also: $$(32)_3 = 32 \cdot 31 \cdot 30 = 29 \, 760 \text{ M\"{o}glichkeiten}$$

Ist die Anzahl an Variationen von $k$ aus $n$ Objekten in einer bestimmten Reihenfolge \emph{mit} Wiederholung gesucht, so gibt es f\"{u}r jedes der $k$ Objekte $n$ M\"{o}glichkeiten: $$n^k \defas \text{Anzahl an Variationen von $k$ aus $n$ Objekten, mit Wiederholung}$$

\subsub{Kombinationen}

Die Anzahl an Kombinationen $\colvec{n \\ k}$ einer Menge von $n$ Objekten ist definiert als die Anzahl an M\"{o}glichkeiten, $k$ Objekte aus den $n$ in \emph{beliebiger} Reihenfolge und ohne Wiederholung auszuw\"{a}hlen. Dieser Wert wird auch \emph{Binomialkoeffizient} genannt. Die Tatsache, dass aus $n$ Objekten $k$ ohne Wiederholung ausgew\"{a}hlt werden sollen, l\"{a}sst auf eine Berechnung \"{a}hnlich jener der Variationen von $k$ aus $n$ Objekten schlie\ss{}en. Diese Anzahl w\"{a}re also gleich $(n)_k$. Da nun aber die Reihenfolge egal ist, muss noch ein weiterer Schritt folgen. Eine beliebige Reihenfolge bedeutet, dass zwei Ereignisse $A_1$ und $A_2$ dasselbe Ereignis sind, wenn $A_2$ eine Permutation von $A_1$ ist. Sei $A_1 = \{\omega_1, \omega_2, \omega_3\}$ und $A_2 = \{ \omega_2, \omega_3, \omega_1\}$. W\"{a}re die Reihenfolge nicht egal, wie bei der Berechnung der Variationen, so w\"{a}ren $A_1$ und $A_2$ separate, von einander komplett verschiedene Ereignisse. Beide w\"{u}rden jeweils als eine M\"{o}glichkeit bzw. eine Variation z\"{a}hlen. Da nun aber bei der Berechnung der Kombinationen die Reihenfolge der $k$ aus $n$ Objekten beliebig sein darf, sind $A_1$ und $A_2$ zueinander equivalent. Somit z\"{a}hlen beide nur als eine einzige Kombinationsm\"{o}glichkeit, nicht als zwei.

Wie wird nun diese Eigenschaft, dass die Reihenfolge der $k$ Objekte egal ist, in die Berchnung der Kombinationen miteinbezogen? Man \"{u}berlege sich, dass es f\"{u}r $k$ Objekte $k!$ M\"{o}glichkeiten gibt, diese $k$ Objekte in ihrer Reihenfolge untereinander umzutauschen --- $k!$ Permutationen. Ist nun also $(n)_k$ die Anzahl an Variationen von $k$ aus $n$ Objekten, so ist die Anzahl an Kombinationen von $k$ aus $n$ Objekten gleich $(n)_k$ dividiert durch die Anzahl an Permutationen der $k$ Objekte: $$\text{Kombinationen } = \frac{\text{Variationen}}{\text{Permutationen}}$$ $$\Downarrow$$ $$ \colvec{n \\ k} = \frac{(n)_k}{k!} = \frac{n \cdot (n - 1) \cdot ... \cdot (n - k + 1)}{k \cdot (k - 1) \cdot ... \cdot 1}$$ Eine bekanntere Schreibweise dieser Formel lautet: $$\colvec{n \\ k} = \frac{n!}{k! \, (n - k)!}$$ Bei n\"{a}herer Analyse dieser Formel zeigt sich, dass sie equivalent zur oberen ist. Expandiert man die Ausdr\"{u}cke $n!$ und $(n - k)!$ der bekannten Formel, so wird klar, dass der Ausdruck $(n - k)!$ die letzten $n - k$ Terme der Fakult\"{a}t von $n$ wegk\"{u}rzt. Sei $n = 5$ und $k = 3$: $$\frac{n!}{k! \, (n - k)!} = \frac{5!}{3! \, (5 - 3)!} = \frac{5 \cdot 4 \cdot 3 \cdot (2 \cdot 1)}{3 \cdot 2 \cdot 1 \cdot (2 \cdot 1)}$$ Die eingeklammerten Terme k\"{u}rzen sich weg: $$\frac{5 \cdot 4 \cdot 3 \cdot \cancel{(2 \cdot 1)}}{3 \cdot 2 \cdot 1 \cdot \cancel{(2 \cdot 1)}} = \frac{5 \cdot 4 \cdot 3}{3 \cdot 2 \cdot 1}$$ Dieser Ausdruck ist nun equivalent zur hergeleiteten Formel. Man setze $n = 5$ und $k = 3$ ein: $$\frac{(n)_k}{k!} = \frac{(5)_3}{3!} = \frac{5 \cdot 4 \cdot 3}{3 \cdot 2 \cdot 1}$$

\beispiel{Vier Personen begr\"{u}\ss{}en einander. Wieviele Begr\"{u}\ss{}ungen sind das?}

Untersucht man die Bedingungen der Kombination der Personen erkennt man: 

\begin{enumerate}
	\item Es gibt keine Wiederholung zwischen einzelnen Personen. Hat Person $A$ Person $B$ begr\"{u}\ss{}t, darf Person $A$ Person $B$ nicht mehr begr\"{u}\ss{}en. Auch kann Person $A$ sich nicht selber begr\"{u}\ss{}en.

	\item Die Reihenfolge der Begr\"{u}\ss{}ungen ist egal. Hat Person $C$ Person $D$ begr\"{u}\ss{}t, muss Person $D$ Person $C$ nicht auch noch begr\"{u}\ss{}en. 
\end{enumerate}

Es gilt also die m\"{o}glichen Kombinationen der Begr\"{u}\ss{}ungen zu suchen, ohne Wiederholung und ohne Reihenfolge der Personen. Wieviele M\"{o}glichkeiten gibt es also, aus vier Personen jeweils zwei nach diesen Bedingungen auszuw\"{a}hlen? $$\colvec{n \\ k} = \colvec{4 \\ 2} = \frac{4!}{2! \, (4 - 2)!} = 6 \text{ M\"{o}glichkeiten}$$

\pagebreak

\sub{Laplace Wahrscheinlichkeit}

Bei einem Laplace'schen Zufallsexperiment hat jedes der $n$ Elementarereignissse $\omega$ aus der Ergebnismenge $\Omega$ die selbe Wahrscheinlichkeit: $$P(\omega) = \frac{1}{n}$$ Sind mehrere Elementarereignisse f\"{u}r ein bestimmtes Ereignis $A$ g\"{u}nstig, so werden die Wahrscheinlichkeiten der einzelnen Elementarereignisse addiert. F\"{u}r $N$ g\"{u}nstige Elementarereignisse $\omega$ eines Ereignisses $A$ gilt somit: $$P(A) = \sum_{\omega \in A} P(\omega) = \sum_{i=0}^{N} \frac{1}{n}$$ Von dieser Summe l\"{a}sst sich die bekannte Laplace'sche Wahrscheinlichkeitsregel herleiten, welche besagt, dass die Wahrscheinlichkeit eines Ereignisses gleich der Anzahl der g\"{u}nstigen F\"{a}lle, dividiert durch die Anzahl der m\"{o}glichen F\"{a}lle ist: $$P(A) = \frac{|A|}{|\Omega|} = \frac{\text{Anzahl der f\"{u}r $A$ g\"{u}nstigen F\"{a}lle}}{\text{Anzahl der m\"{o}glichen F\"{a}lle}}$$

\beispiel{Wie gro\ss{} ist die Wahrscheinlichkeit, vier mal hintereinander eine ungerade Zahl zu w\"{u}rfeln?}

Die Ergebnismenge $\Omega$ umfasst alle 6 m\"{o}glichen Augenzahlen des W\"{u}rfels: $$\Omega = \{ 1, 2, 3, 4, 5, 6\}$$ F\"{u}r das gesuchte Ereignis $A$ ist es g\"{u}nstig, entweder eine 1, eine 3 oder eine 5 zu w\"{u}rfeln. Die Anzahl der g\"{u}nstigen ist also 3. Die Wahrscheinlichkeit f\"{u}r $A$ betr\"{a}gt daher: $$P(A) = P(\{1, 3, 5\}) = \frac{|A|}{|\omega|} = \frac{3}{6} = 0.5$$ Dieses Ereignis soll vier mal hintereinander wiederholt werden: $$P(A)^4 = 0.5^4 = 0.5 \cdot 0.5 \cdot 0.5 \cdot 0.5 = 0.0625$$

\beispiel{In einer Klasse sind 12 M\"{a}dchen und 15 Knaben. 5 Personen werden gepr\"{u}ft, wie gro\ss{} ist die Wahrscheinlichkeit, dass 2 M\"{a}dchen und 3 Burschen gepr\"{u}ft werden?} 

Die Ergebnismenge $\Omega$ umfasst hier alle 12 Sch\"{u}lerinnen und 15 Sch\"{u}ler der Klasse: $$\Omega = \{M, M, M, \dots, K, K, K\}$$ F\"{u}r das gew\"{u}nschte Ereignis g\"{u}nstig ist jene Teilmenge von $\Omega$, welche zwei M\"{a}dchen und 3 Burschen umfasst: $$A = \{ M, M, K, K, K\}$$ Die W\"{a}hrscheinlichkeit dieses Ereignisses $A$ betr\"{a}gt nach den Laplace Regeln: $$P(A) = \left(\frac{12}{27} \cdot \frac{11}{26} \cdot \frac{15}{25} \cdot \frac{14}{24} \cdot \frac{13}{23}\right)$$ Die Anzahl an M\"{o}glichen verringert sich bei jeder Durchf\"{u}hrung des Zufallsversuchs, da ein Sch\"{u}ler nicht zwei mal gepr\"{u}ft werden kann. Nun muss jedoch ber\"{u}cksichtigt werden, dass es f\"{u}r die 2 M\"{a}dchen und 3 Buben noch mehrere Kombinationen gibt. Diese Anzahl an Kombinationen l\"{a}sst sich durch den Binomialkoeffizienten beschreiben. $n$ ist dabei 5 und $k$ entweder 3 oder 2. Die Wahrscheinlichkeit, dass 2 M\"{a}dchen und 3 Burschen gepr\"{u}ft werden, betr\"{a}gt somit: $$P(A) = \colvec{5 \\ 2} \cdot \left(\frac{12}{27} \cdot \frac{11}{26} \cdot \frac{15}{25} \cdot \frac{14}{24} \cdot \frac{13}{23}\right) = 0.372$$

\pagebreak

\sub{Baumdiagramme und Pfadregeln}

Bei mehrstufigen Zufallsversuchen ist es oft vorteilhaft, die einzelnen Stufen und deren Ab\"{a}ngigkeiten in einem Baumdiagramm zu visualisieren. Daf\"{u}r seien zwei Regeln definiert:

\begin{enumerate}
	\titleitem{Summenregel} Die Wahrscheinlichkeit, dass Ereignis $A$ oder Ereignis $B$ eintritt, ist gleich der Summe der einzelnen Wahrscheinlichkeiten: $P(A \lor B) = P(A) + P(B)$

	\titleitem{Produktregel} Die Wahrscheinlichkeit, dass Ereignis $A$ und Ereignis $B$ eintritt, ist gleich dem Produkt der einzelnen Wahrscheinlichkeiten: $P(A \land B) = P(A) \cdot P(B)$
\end{enumerate}

\beispiel{In einer Urne liegen 4 rote und 6 blaue Kugeln. Drei Kugeln werden ohne Zur\"{u}cklegen gezogen. Wie gro\ss{} ist die Wahrscheinlichkeit, zuerst eine rote, dann eine blaue, dann eine rote zu ziehen (1)? Wie gro\ss{} ist die Wahrscheinlichkeit, nur gleichfarbige Kugeln zu ziehen (2) ?}

Bei diesen Beispielen liegen herk\"{o}mmliche Laplace Wahrscheinlichkeiten vor. Es gibt insgesamt $n$ Kugeln, wobei jedes Elementarereignis $\omega$ (jede Kugel) aus der Ergebnismenge $\Omega$ eine Wahrscheinlichkeit von $n^{-1}$ hat. F\"{u}r das erste m\"{o}gliche Ereignis $A$, dass eine rote Kugel gezogen wird, sind vier Elementarereignisse g\"{u}nstig. F\"{u}r das zweite Ereignis $B$, dass eine blaue Kugel gezogen wird, sind sechs $\omega$ g\"{u}nstig. Die Anzahl an M\"{o}glichen betr\"{a}gt 10. Somit kann f\"{u}r die Wahrscheinlichkeiten der einzelnen Ereignisse festgelegt werden: $$P(A) = \frac{4}{10} \hspace{2cm} P(B) = \frac{6}{10}$$ Nun ist aber die Wahrscheinlichkeit von mehreren bestimmten Ereignissen hintereinander gefragt. Wichtig ist, dass die Kugeln ohne Zur\"{u}cklegen gezogen werden. Das bedeutet, dass die Anzahl an Kugeln pro Ziehung schrumpft, somit auch die Wahrscheinlichkeiten der beiden m\"{o}glichen Ereignisse. Problemstellung $(1)$ fragt nach der Wahrscheinlichkeit, dass zuerst Ereignis $A = Rot$, dann Ereignis $B = Blau$ und dann wieder Ereignis $A$ eintritt. Man bemerke, dass hierbei die Reihenfolge wichtig ist. Daher muss dem Baumdiagramm genau in dieser Reihung gefolgt werden. Da die Ereignisse hier w\"{o}rtlich mit einem \zitat{und} verbunden werden (Ereignis $A$ und dann $B$ und dann $A$), muss die Produktregel angewandt werden. Man kann den gew\"{u}nschten Pfad in einem Baumdiagramm visualisieren:

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}[scale=1.5]

		\draw [fill=red, very thick]
			  (1.5, 2) circle [radius=0.25cm];

		\draw [dashed, very thick, red]
		      (1.5, 2.25)
		   -- (3.5, 3) node [pos=0.25, above left] 
		   		     	    {$\frac{4}{10}$};

        \draw [fill=cyan, very thick]
			  (5.5, 2) circle [radius=0.25cm]
			  (5.5, 2.25)
		   -- (3.5, 3) node [pos=0.25, above right] 
		   					{$\frac{6}{10}$};

		 \newcount\current

		\foreach \i/\a/\b in {0.5/$\frac{3}{9}$/$\frac{6}{9}$,
						      4.5/$\frac{4}{9}$/$\frac{5}{9}$}
		{
			\draw [fill=red, very thick]
				  (\i, 1) circle [radius=0.25cm]
				  (\i, 1.25)
			   -- (\i + 0.82322, 1.82322) node [pos=0.25, above left] {\a};

			\draw [fill=cyan, very thick]
				  (\i+2, 1) circle [radius=0.25cm];

			\current \i\relax

			\ifnum\current=0.5
				\draw [very thick, dashed, cyan]
				      (\i+2, 1.25)
			       -- (\i + 1.17677,1.82322) node [pos=0.25, above right] {\b};

			\else
				\draw [very thick]
				  	  (\i+2, 1.25)
			   	   -- (\i + 1.17677,1.82322) node [pos=0.25, above right] {\b};
			\fi
		}

		\foreach \i/\a/\b in {0/$\frac{2}{8}$/$\frac{6}{8}$,
		 				      2/$\frac{3}{8}$/$\frac{5}{8}$,
		 				      4/$\frac{3}{8}$/$\frac{5}{8}$,
		 				      6/$\frac{4}{8}$/$\frac{4}{8}$}
		{
			\draw [fill=red, very thick]
				  (\i, 0) circle [radius=0.25cm];

			\current \i\relax

			\ifnum\current=2
				\draw [very thick, dashed, red]
				       (\i, 0.25)
			        -- (\i+0.32322,0.82322) node [pos=0.25, above left]  {\a};
			\else
				\draw [very thick]
				       (\i, 0.25)
			        -- (\i+0.32322,0.82322) node [pos=0.25, above left]  {\a};
			\fi

            \draw [fill=cyan, very thick]
				  (\i+1, 0) circle [radius=0.25cm]
				  (\i+1, 0.25)
			   -- (\i + 0.67677, 0.82322) node [pos=0.25, above right] {\b};
		}

	\end{tikzpicture}
\end{figure}

\vspace{\parskip}

Die Wahrscheinlichkeit betr\"{a}gt also: $${\color{red} \frac{4}{10}} \cdot {\color{cyan} \frac{6}{9}} \cdot {\color{red} \frac{3}{8}} = 0.1 = 10 \%$$

\pagebreak

Die zweite Problemstellung erfordert die Anwendung der Summenregel. Dies folgt daraus, dass es hier mehrere (zwei) M\"{o}glichkeiten gibt, die gew\"{u}nschte Serie an Ereignissen zu bilden (\zitat{Alle rot \emph{oder} alle blau}). Diese Ereignisserien k\"{o}nnen unabh\"{a}ngig von einander eintreten, ihre Wahrscheinlichkeiten werden also nach der Summenregel addiert. Die einzelnen Wahrscheinlichkeiten der Ereignisse dieser Serien werden wie gehabt nach der Produktregel multipliziert. Orientiert man sich an einem Baumdiagramm, so w\"{a}ren die beiden g\"{u}nstigen Pfade jene, die immer links (rot) oder immer rechts (blau) gehen:

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}[scale=1.5]

		\draw [fill=red, very thick]
			  (1.5, 2) circle [radius=0.25cm];

		\draw [dashed, very thick, red]
		      (1.5, 2.25)
		   -- (3.5, 3) node [pos=0.25, above left] 
		   		     	    {$\frac{4}{10}$};

        \draw [fill=cyan, very thick]
			  (5.5, 2) circle [radius=0.25cm];

		\draw [very thick, cyan, dashed]
			  (5.5, 2.25)
		   -- (3.5, 3) node [pos=0.25, above right] 
		   					{$\frac{6}{10}$};

		 \newcommand{\settings}{}
		 \newcount\current

		\foreach \i/\a/\b in {0.5/$\frac{3}{9}$/$\frac{6}{9}$,
						      4.5/$\frac{4}{9}$/$\frac{5}{9}$}
		{
			\current \i\relax

			\draw [very thick, fill=red]
				  (\i, 1) circle [radius=0.25cm];

			\ifnum\current=0.5
				\renewcommand{\settings}{[very thick, dashed, red]}
			\else
				\renewcommand{\settings}{[very thick]}
			\fi

			\draw \settings
				  (\i, 1.25)
			   -- (\i + 0.82322, 1.82322) node [pos=0.25, above left] {\a};

			\draw [very thick, fill=cyan]
				  (\i+2, 1) circle [radius=0.25cm];

			\ifnum\current=4.5
				\renewcommand{\settings}{[very thick, dashed, cyan]}

			\else
				\renewcommand{\settings}{[very thick]}

			\fi

			\draw \settings
				  (\i+2, 1.25)
			   -- (\i+1.17677,1.82322) node [pos=0.25, above right] {\b};
		}

		\foreach \i/\a/\b in {0/$\frac{2}{8}$/$\frac{6}{8}$,
		 				      2/$\frac{3}{8}$/$\frac{5}{8}$,
		 				      4/$\frac{3}{8}$/$\frac{5}{8}$,
		 				      6/$\frac{4}{8}$/$\frac{4}{8}$}
		{
			\current \i\relax

			\draw [very thick, fill=red]
				  (\i, 0) circle [radius=0.25cm];

			\ifnum\current=0
				\renewcommand{\settings}{[very thick, dashed, red]}
				
			\else
				 \renewcommand{\settings}{[very thick]}
			\fi

			\draw \settings
				  (\i, 0.25)
			   -- (\i+0.32322,0.82322) node [pos=0.25, above left]  {\a};

			\draw [fill=cyan, very thick]
				  (\i+1, 0) circle [radius=0.25cm];

			\ifnum\current=6
				\renewcommand{\settings}{[very thick, dashed, cyan]}
			\else
			    \renewcommand{\settings}{[very thick]}
			\fi			

			\draw \settings
				  (\i+1, 0.25)
			   -- (\i+0.67677,0.82322) node [pos=0.25, above right] {\b};
		}

	\end{tikzpicture}
\end{figure}

\vspace{\parskip}

Die Wahrscheinlichkeit betr\"{a}gt daher: $$\left({\color{red} \frac{4}{10}} \cdot {\color{red} \frac{3}{9}} \cdot {\color{red} \frac{2}{8}}\right) + \left({\color{cyan} \frac{6}{10}} \cdot {\color{cyan}\frac{5}{9}} \cdot {\color{cyan}\frac{4}{8}}\right) = 0.2 = 20 \%$$

\sub{Diskrete Zufallsvariablen}

Eine diskrete Zufallsvariable $X$, auch \emph{Zufallsgr\"{o}\ss{}e} genannt ist eine Abbildung der Ergebnismenge auf die Menge der nat\"{u}rlichen Zahlen: $$X: \Omega \rightarrow \mathbb{N}$$ Die Ergebnismenge $\Omega$ muss nun z\"{a}hlbare Werte enthalten, die als nat\"{u}rliche Zahlen repr\"{a}sentiert werden k\"{o}nnen. Die Ereignismenge von zwei W\"{u}rfeln k\"{o}nnte ihre Zahlenmenge enthalten, welche als nat\"{u}rliche Zahl darstellbar ist. Gegens\"{a}tzlich dazu l\"{a}sst sich die Ereignismenge $\Omega = \{ \text{Kopf, Zahl} \}$ eines M\"{u}nzwurfs nicht direkt einer Zufallsvariable zuordnen. Es ist jedoch dennoch m\"{o}glich, wenn man die Elementarereignisse enumeriert, sodass Kopf $= 0$ und $Zahl = 1$ und somit $\Omega = \{0 , 1\}$. Die Wahrscheinlichkeit $P$, mit der die Zufallsvariable $X$ den Wert $x \in \mathbb{N}$ annimmt, wird durch die Wahrscheinlichkeitsfunktion $p: \mathbb{N} \rightarrow [0 ; 1]$ beschrieben. Die Funktion $f$ bildet also die Menge der nat\"{u}rlichen Zahlen --- jene Werte, welche die diskrete Zufallsvariable $X$ annehmen kann --- auf das Intervall $[0 ; 1]$ ab. Die Funktion $p(x)$ wird dabei die \emph{Wahrscheinlichekeitsverteilung} der Zufallsvariable genannt: $$p(x) = P(X = x)$$ Es sei angemerkt, dass die Wahrscheinlichkeitsfunktion bzw. -verteilung nur f\"{u}r die Elemente der Ergebnismenge $\Omega$ Werte gr\"{o}\ss{}er null annimmt. Dies folgt daraus, dass die Wahrscheinlichkeit f\"{u}r ein Ereignis $A$, dass Elementarereignisse umfasst, die nicht $\in \Omega$ sind, gleich null sein muss. So kann ein W\"{u}rfel beispielsweise nie die Zahl 7 annehmen, daher ist $P(X = 7) = 0$. Dasselbe gilt f\"{u}r alle $x < 1$ sowie alle $x > 6$.

\pagebreak

Der folgende Graph bildet die Wahrscheinlichkeitsverteilung f\"{u}r eine diskrete Zufallsvariable $X$ im Zusammenhang mit dem Ziehen einer Kugel aus einer Urne ab. In dieser Urne befinden sich insgesamt 10 Kugeln, von denen 3 blau, 5 rot und 2 gr\"{u}n sind. $X$ ordnet dabei jedem Elementarereignis $\omega$ der Ergebnismenge $\Omega = \{\text{Blau, Rot, Gr\"{u}n}\}$ einen entsprechenden Definitionswert $\in \mathbb{N}$ zu. Da die Elementarereignisse hier keine Zahlen sind, m\"{u}ssen sie enumeriert werden. Sei also Blau $= 1$, Rot $= 2$ und Gr\"{u}n $= 3$. Nun sind alle $\omega \in \mathbb{N}$, k\"{o}nnen also als Definitionswerte bzw. $x$-Werte in einem Funktionsgraphen abgebildet werden. Die Wahrscheinlichkeitsfunktion $p(x)$ ordnet dann jedem dieser Definitionswerte einen entsprechenden Funktionswert zu, welcher die Wahrscheinlichkeit beschreibt, dass die Zufallsvariable $X$ diesen Definitionswert $x$ annimmt:

\begin{figure}[h!]
	\centering
	\begin{tikzpicture}
		\begin{axis}
		[
			width=15cm,
			height=6cm,
			xlabel={$x$},
			xmin=0,
			xmax=5,
			xtick={0, 1, ..., 5},
			ylabel={$p(x) \rightarrow P(X = x)$},
			ymin=0,
			ymax=0.75,
			grid = both,
			axis lines=middle
		]

			\addplot [mark=*, blue] coordinates {(1, 3/10)};

			\addplot [mark=*, red] coordinates {(2, 5/10)};

			\addplot [mark=*, nicegreen] coordinates {(3, 2/10)};

		\end{axis}
	\end{tikzpicture}
\end{figure}

\subsub{Erwartungswert}

Der Erwartungswert $\mu$ oder $E(x)$ einer diskreten Zufallsvariable $X$ gibt an, welchen Wert die Zufallsvariable eines Zufallsversuchs durchschnittlich am h\"{a}ufigsten annimmt, welcher Wert also zu \emph{erwarten} ist. $\mu$ wird berechnet, indem man die Summe aller Wahrscheinlichkeiten der f\"{u}r $X$ m\"{o}glichen Werte, also alle $x \in \mathbb{N}$, multipliziert mit ihrem Wert berechnet. Da es kein gr\"{o}\ss{}tes $x \in \mathbb{N}$ gibt, ist diese Summe theoretisch unendlich: $$\mu = \sum_{x=0}^{\infty} p(x) \cdot x = \sum_{x=0}^{\infty} P(X = x) \cdot x = P(X = 0) \cdot 0 + P(X = 1) \cdot 1 + P(X = 2) \cdot 2 + \dots$$ Praktisch gesehen sind die Wahrscheinlichkeiten aller Werte, die nicht $\in \Omega$, jedoch gleich null. Somit berechnet man in der Praxis den Erwartungswert nur f\"{u}r die $N$ m\"{o}glichen Elementarereignisse $\omega$ aus der Ergebnismenge $\Omega$: $$\mu = \sum_{i=1}^{N} p(\omega_i) \cdot i \hspace{1cm} \text{mit } \omega \in \Omega$$

\subsub{Standardabweichung und Varianz}

Die Standardabweichung $\sigma$ einer diskreten Zufallsvariable $X$ ist jener Wert, um welchen $X$ durschnittlich um den Erwartungswert $\mu$ schwankt. $X$ wird wie gesagt bei bei einer langen Verssuchsserie mit relativ hoher Wahrscheinlichkeit den Wert $\mu$ annehmen. Mit noch h\"{o}herer Wahrscheinlichkeit wird $X$ im Intervall $[\mu - \sigma ; \mu + \sigma]$ liegen. Um die Standardabweichung zu berechnen, multipliziert man die Wahrscheinlichkeit jeden f\"{u}r $X$ m\"{o}glichen Werts $x \in \mathbb{N}$, mit der Differenz zwischen $x$ und dem Erwartungswert $\mu$, zum Quadrat. $\sigma$ ist dann die Wurzel von diesem Wert. Die Differenz muss quadriert werden, damit sich das Vorzeichen aufhebt. Ansonsten k\"{o}nnten negative $x - \mu$ positive $x - \mu$ aufheben, was das Ergebnis verf\"{a}lschen w\"{u}rde. Das Ziehen der Wurzel hebt die Quadrierung wieder auf. Theoretisch: $$\sigma = \sqrt{\sum_{x=0}^{\infty} p(x) \cdot (x - \mu)^2} = \sqrt{p(0) \cdot (0 - \mu)^2 + p(1) \cdot (1 - \mu)^2 + \dots}$$ Der Unterschied zur Praxis ist der selbe wie bei der Berechnung von $\mu$. Es sei angemerkt, dass die Subtraktion mit $\mu$ bzw. $\mu^2$ aus der obigen Berechnung herausgehoben werden und an das Ende der Summe gestellt werden kann. Somit muss man nicht die Differenz zwischen $x$ und $\mu$ f\"{u}r jeden Term berechnen: $$\sigma = \sqrt{\left( \sum_{x=0}^{\infty} p(x) \cdot x^2\right) - \mu^2} = \sqrt{\big[ p(0) \cdot 0^2 + p(1) \cdot 1^2 + \dots \big] - \mu^2}$$

Die Varianz $V$ bzw. $\sigma^2$ ist das Quadrat der Standardabweichung. Es hat keinen praktischen Nutzen, da es Einheiten zum Quadrat (Quadrat-IQ, Quadrat-Augensumme, \dots) beschreibt und nicht die eigentlichen Einheiten (IQ, Augensumme, \dots).

\subsub{Bewertungsfunktion}

Eine Bewertungsfunktion $g(x)$ einer diskreten Zufallsvariable $X$ ordnet jedem m\"{o}glichem Wert der Zufallsvariable eine bestimmte Wertung zu, oftmals einen Geldpreis. Ein Beispiel f\"{u}r eine Bewertungsfunktion sind die Preise bei einem Gewinnspiel. So k\"{o}nnte es ein Gewinnspiel geben, bei dem es gilt, mit zwei W\"{u}rfeln eine bestimmte Augensumme zu w\"{u}rfeln. Der Einsatz ist 1\euro. Betr\"{a}gt die Augensumme eines Wurfes 7, so erh\"{a}lt man 5\euro. Bei jeder anderen Augensumme verliert man seinen Einsatz. Die Zufallsvariable $X$ beschreibt hierbei die Augensumme. Mit zwei W\"{u}rfeln gibt es 36 verschiedene M\"{o}glichkeiten, eine Augensumme zu bilden. Von diesen sind 6 Kombinationen g\"{u}nstig f\"{u}r das Ereignis, dass die Zufallsvariable $X$ den Wert 7 annimmt: $$A_7 = \{(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)\}$$ Die Wahrscheinlichkeit, dass die Augensumme 7 betr\"{a}gt ist daher 6 Zehntel. Die Wahrscheinlichkeit, dass die Augensumme nicht 7 betr\"{a}gt, muss die restlichen m\"{o}glichen Augensummen umfassen, also 30 Zehntel. Somit gilt f\"{u}r die Wahrscheinlichkeiten: $$P(X = 7) = \frac{6}{36} \hspace{2cm} P(X \neq 7) = 1 - P(X = 7) = \frac{30}{36}$$ Mit welcher Geldsumme steigt man bei diesem Gewinnspiel also erwartungsgem\"{a}\ss{} aus? Um diese Frage zu beantworten, berechnet man den Erwartungswert $\mu$ der Gewinnfunktion. Hierbei multipliziert man die Wahrscheinlichkeit jedes Ereignisses mit dem entsprechenden Funktionswert der Bewertungsfunktion. In diesem Fall w\"{a}re der Erwartungswert gleich der Wahrscheinlichkeit, dass die Augensumme den Wert 7 erreicht, mal 4\euro, plus der Wahrscheinlichkeit, dass die Augensumme einen anderen Wert als 7 annimmt, mal -1\euro. Die letzte Geldsumme ist dabei negativ, weil man einen Euro Einsatz verliert. Die erste Geldsumme ist nur vier und nicht f\"{u}nf Euro, weil man seinen Einsatz bei diesem Spiel nicht zur\"{u}ckerh\"{a}lt. Der Erwartungswert ist somit: $$\mu = \sum_{i=1}^{N} p(A_i) \, \cdot \, g(A_i) = \left(\frac{6}{36} \cdot 4 \text{\euro} \right) + \left(\frac{30}{6} \cdot (-1) \text{\euro}\right) \approx -0.17\text{\euro}$$ wo $N$ die Anzahl an Ereignissen ist (hier gleich 2: Ereignis $A$ und Gegenereignis $A'$). Man kann also erwarten, dass wenn man an diesem Gewinnspiel sehr oft teilnimmt, man ungef\"{a}hr 17 Cent verliert.

\pagebreak

\sub{Binomialverteilung}

Die Binomialverteilung ist eine besondere Wahrscheinlichkeitsverteilung, welche nur unter den folgenden beiden Bedingungen gegeben ist:

\begin{enumerate}

	\titleitem{Nur zwei m\"{o}gliche Ereignisse}

	Es darf nur zwei m\"{o}gliche Ereignisse $A$ und $A'$ geben. Ereignis $A$ hat eine Wahrscheinlichkeit von $p$. Ereignis $A'$ ist das Gegenereignis von $A$ und hat daher eine Wahrscheinlichkeit von $1 - p$. Ein solcher Zufallsversuch nennt sich \emph{Bernoulli Experiment}.

	\titleitem{Konstante Wahrscheinlichkeit bei jeder Iteration}

	Die Wahrscheinlichkeit f\"{u}r ein bestimmtes Ereignis $A$ muss bei jeder Durchf\"{u}hrung einer Serie konstant bleiben. So w\"{a}re beispielsweise eine Serie von Griffen aus einer Urne mit $n$ Kugeln nur dann binomialverteilt, wenn nach jedem Griff die Kugel zur\"{u}ckelegt wird. Ansonsten w\"{u}rde sich die Gesamtanzahl an Kugeln $n$ nach jedem Griff ver\"{a}ndern, somit auch die Wahrscheinlichkeit f\"{u}r ein bestimmtes Ereignis.
\end{enumerate}

Bei der Binomialverteilung spielt der Binomialkoeffizient eine wichtige Rolle, welcher die Anzahl an M\"{o}glichkeiten beschreibt, aus $n$ Elementen $k$ in beliebiger Reihenfolge und ohne Wiederholung einzelner Elemente auszuw\"{a}hlen. Die Variablen $n$ und $k$ beschreiben hierbei immer eine Anzahl an Ereignissen. Diese und andere Tatsachen die Binomialverteilung betreffend seien an einem Beispiel demonstriert.

\textbf{Beispiel}: \emph{Bei einem Quiz werden 5 Fragen gestellt. Bei jeder Frage stehen 3 Antworten zur Auswahl, von denen je eine richtig ist. Ein Kandidat kreuzt rein zuf\"{a}llig an. Wie gro\ss{} ist die Wahrscheinlichkeit, dass er bei mindestens zwei Fragen die richtige Option ankreuzt?}

Zuerst muss \"{u}berpr\"{u}ft werden, ob wirklich eine Binomialverteilung vorliegt. Die erste Bedingung besagt, dass es nur zwei m\"{o}gliche Ereignisse f\"{u}r jede Iteration des Zufallsversuchs geben darf. Anhand des Textes erkennt man, dass man eine Frage entweder richtig oder falsch beantworten kann. Es liegt also ein Bernoulli Experiment vor, somit ist die erste Bedingung erf\"{u}llt. F\"{u}r die Erf\"{u}llung der zweiten Bedingung muss die Wahrscheinlichkeit der beiden Ereignisse bei jeder Durchf\"{u}hrung des Experiments gleich bleiben. Bei der ersten Frage betr\"{a}gt die Wahrscheinlichkeit, sie bei zuf\"{a}lligem Ankreuzen richtig zu beantworten, ein Drittel. Bei der zweiten Frage ist dies ebenso der Fall. Bei der dritten Frage auch und bei den beiden letzten ebenso. Somit ist auch die zweite Bedingung erf\"{u}llt: es liegt also eine Binomialverteilung vor.

Die diskrete Zufallsvariable $X$ soll hier die Anzahl an richtig angekreuzten Fragen beschreiben. Gesucht ist die Wahrscheinlichkeit, dass $X$ einen Wert gr\"{o}\ss{}er oder gleich 2 annimmt. Dies sei das Ereignis $A$. Die Wahrscheinlichkeit dieses Ereignisses ist equivalent zu jener, dass $X$ gleich zwei, drei, vier oder f\"{u}nf ist. Man erkennt, dass es hier leichter ist, mit dem Gegenereignis $A'$ sowie mit der Gegenwahrscheinlichkeit $1 - P(A)$ zu rechnen. Das Gegenereignis ist jenes, dass $X$ nicht gr\"{o}\ss{}er oder gleich 2 ist, sondern kleiner. Die Wahrscheinlichkeit des Gegenereignisses ist also equivalent jener, dass $X$ gleich 0 oder 1 ist: $$P(X \geq 2) = P(X=2) + P(X=3) + P(X=4) + P(X=5)$$ $$P(X \geq 2) = 1 - P(X < 2) = 1 - [P(X=0) + P(X=1)]$$ Die Wahrscheinlichkeit $P(X = 0)$, dass keine Frage richtig beantwortet wird, tritt ein, wenn sowohl Frage 1, als auch 2, 3, 4 und letztlich 5 falsch beantwortet werden. Die Wahrscheinlichkeit f\"{u}r die falsche Beantwortung einer Frage betr\"{a}gt jeweils zwei Drittel, weil zwei von drei Antworten jeder Frage falsch sind. $P(X = 0)$ betr\"{a}gt daher: $$\frac{2}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} = \left(\frac{2}{3}\right)^5 \approx 0.132$$

Eine m\"{o}gliche Konstellation von richtig oder falsch beantworteten Fragen, die die Wahrscheinlichkeit $P(X = 1)$ erf\"{u}llen w\"{u}rde, w\"{a}re dass die erste Frage richtig beantwortet wird und die folgenden vier falsch. Dies w\"{a}re so berechnet: $$\frac{1}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} = \left(\frac{1}{3}\right) \left(\frac{2}{3}\right)^4$$ Eine weitere M\"{o}glichkeit w\"{a}re es, dass die dritte Frage richtig beantwortet wird und die anderen nicht: $$\frac{2}{3} \cdot \frac{2}{3} \cdot \frac{1}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} = \left(\frac{1}{3}\right) \left(\frac{2}{3}\right)^4$$ Es wird klar, dass mehrere M\"{o}glichkeiten gibt, die Wahrscheinlichkeit $P(X = 1)$ zu bilden. Die Anzahl dieser M\"{o}glichkeiten wird durch den Binomialkoeffizient beschrieben. Wiederholt man die Defintion des Binomialkoeffizienten aus der Sektion \"{u}ber Kombinatorik, so lautet diese: \zitat{Der Binomialkoeffizient $\colvec{n \\ k}$ beschreibt die Anzahl an M\"{o}glichkeiten, aus $n$ Objekten $k$ in beliebiger Reihenfolge und ohne Wiederholung einzelner Elemente auszuw\"{a}hlen.} Die Elemente sind in diesem Fall die Fragen des Quiz. Die Zahl $n$ betr\"{a}gt f\"{u}nf, da es f\"{u}nf verschiedene Fragen gibt. Der Wert von $k$ ist in diesem Fall 1, weil es gilt, aus den f\"{u}nf Fragen eine zu auszuw\"{a}hlen. Es gibt daher $$\colvec{5 \\ 1} = \frac{5!}{1! (5 - 1)!} = 5$$ M\"{o}glichkeiten, aus den f\"{u}nf Fragen eine (richtig beantwortete) auszuw\"{a}hlen. Dieser Wert wird den Wahrscheinlichkeiten der einzelnen Fragen als \emph{Koeffizient} vorangestellt: $$5 \cdot \left(\frac{1}{3}\right) \cdot \left(\frac{2}{3}\right)^4 \approx 0.329$$ Die Wahrscheinlichkeit des Gegenereignisses $A'$ betr\"{a}gt somit in Summe: $$P(A') = P(X=0) + P(X=1) \approx 0.132 + 0.329 \approx 0.461$$ Die Wahrscheinlichkeit  des Ereignisses, dass der Kandidat mindestens zwei Fragen richtig ankreuzt ist nun: $$P(A) = 1 - P(A') \approx 1 - 0.461 \approx 0.538 \approx 53.8 \%$$ Der Kandidat wird also mit einer Wahrscheinlichkeit von ungef\"{a}hr $53.8\%$ mindestens zwei der f\"{u}nf Fragen richtig beantworten.

Es sei nun noch die allgemeine Formel zur Berechnung einer binomialverteilten Wahrscheinlichkeit gegeben: $$P(A) = P(X=k) = \colvec{n \\ k} \cdot p^k \cdot (1-p)^{n-k}$$ Hierbei dr\"{u}ckt $n$ eine Anzahl an Iterationen des Zufallsversuch aus; $k$ die Anzahl Versuchen, die von den maximal $n$ Versuchen f\"{u}r das Ereignis $A$ g\"{u}nstig ausgehen sollen; $\colvec{n \\ k}$ somit die Anzahl an M\"{o}glichkeiten, aus den $n$ Versuchen $k$ f\"{u}r das Ereignis $A$ g\"{u}nstige auszuw\"{a}hlen; $p$ die Wahrscheinlichkeit, mit der das Ereignis $A$ eintritt; $1-p$ die Wahrscheinlichkeit, mit der das Gegenereignis $A'$ von $A$ eintritt. Es gibt $k$ Versuche, die f\"{u}r das Ereignis $A$ mit der Wahrscheinlichkeit $p$ g\"{u}nstig ausgehen. Daher wird diese Wahrscheinlichkeit $p$ zur $k$-ten Potenz gestellt. Beispielsweise f\"{u}r $k=3$: $$\{\text{g\"{u}nstig f\"{u}r } A, \text{g\"{u}nstig f\"{u}r } A, \text{g\"{u}nstig f\"{u}r } A\} = p \cdot p \cdot p = p^3$$ Gehen von $n$ Versuchen $k$ f\"{u}r das Ereignis $A$ g\"{u}nstig aus, so m\"{u}ssen die restlichen $n-k$ f\"{u}r das Gegenereignis $A'$ g\"{u}nstig bzw. f\"{u}r das Ereignis $A$ ung\"{u}nstig ausgehen. Ist die Wahrscheinlichkeit des Ereignisses $A$ gleich $p$, so ist jene des Gegenereignisses $A'$ gleich $1 - p$. Diese Wahrscheinlichkeit des Gegenereignisses soll $n-k$ mal vorkommen, wird also hoch $n-k$ genommen. Beispielsweise f\"{u}r $n=5$ und $k=3$: $$\{\text{ung\"{u}nstig f\"{u}r } A, \text{ung\"{u}nstig f\"{u}r } A\} = \{\text{g\"{u}nstig f\"{u}r } A', \text{g\"{u}nstig f\"{u}r } A'\} = (1-p) (1-p) = (1-p)^{5-3} = (1-p)^2$$ Der Binomialkoeffizient $\colvec{n \\ k}$ stellt sicher, dass alle m\"{o}glichen Kombinationen der $k$ aus $n$ Objekte ber\"{u}cksichtigt werden.

Bei der Binomialverteilung gibt es f\"{u}r das Ereignis sowie f\"{u}r das Gegenereignis nur zwei vordefinierte Wahrscheinlichkeiten $p$ bzw. $1 - p$. Daher haben der Erwartungswert und die Standardabweichung einer binomialverteilten Zufallsvariable eine einfachere Definition als f\"{u}r anders verteilte Zufallsvariablen: $$\mu = n \cdot p$$ $$\sigma = \sqrt{n \cdot p \cdot (1-p)} = \sqrt{\mu \cdot (1 - p)}$$ Hierbei ist $n$ die Anzahl an Zufallsversuchen (beispielsweise die \emph{f\"{u}nf} Quizfragen).

\end{document}