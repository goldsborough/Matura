% Normalverteilung

\input{preamble.tex}

\begin{document}
\thispagestyle{plain}

\heading{Normalverteilung}

Viele Zufallsprozesse oder andere nat\"{u}rliche Verteilungen folgen ann\"{a}hernd einer Glockenkurve, sind also \textbf{normalverteilt}. Eine Zufallsvariable $X$ ist normalverteilt mit einem Erwartungs- bzw. Mittelwert $\mu$ und einer Standardabweichung $\sigma$ --- die durchschnittlich zu erwartende Streuung der Messwerte um den Erwartungswert --- wenn ihre Wahrscheinlichkeit, einen Wert aus dem Intervall $[x_{0} ; x_{1}]$ anzunehmen, folgenderma\ss{}en ausgedr\"{u}ckt werden kann: $$P(x_{0} \leq X \leq x_{1}) = \frac{1}{\sigma \cdot \sqrt{2\pi}} \cdot e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}$$

\begin{tabular}{l p{11cm}}
	\textbf{Erwartungswert $\mu$} & \defas der durschnittlich zu erwartende Wert der Zufallsvariable $X$
	\\ & \\
	\textbf{Standardabweichung $\sigma$} & \defas die durschnittlich zu erwartende Abweichung der Zufallsvariable $X$ vom Erwartungswert $\mu$
	\\ & \\
	\textbf{$X \sim \mathcal{N}(\mu; \sigma)$} & \defas eine normalverteilte Zufallsvariable $X$ mit den Parametern $\mu$ und $\sigma$
\end{tabular}

Es ist wichtig anzumerken, dass eine normalverteilte Zufallsvariable nicht diskret, sondern stetig ist. Eine diskrete Zufallsvariable, beispielsweise jene bei der binomialen oder hypergeometrischen Verteilung, kann nur nat\"{u}rliche Zahlenwerte aus einer vordefinierten Teilmenge $\Omega \subset \mathbb{N}$ annehmen, der sogenannten \emph{Ereignismenge}. Gegens\"{a}tzlich dazu kann eine stetige Zufallsvariable alle m\"{o}glichen Werte aus der Menge der reellen Zahlen $\mathbb{R}$ annehmen, da sie durch Messung entsteht. Da man zwischen zwei reellen Zahlen stets eine weitere reelle Zahl einf\"{u}gen kann, ist die Anzahl an m\"{o}glichen Werten f\"{u}r eine reelle Zahl unendlich. So kann man beispielsweise bei einer stetigen Zufallsvariable, f\"{u}r welche die Grundmenge $\mathbb{G}$ die Menge der reellen Zahlen $\mathbb{R}$ ist, niemals einen Wasserstand, eine F\"{u}llmenge oder eine Baumh\"{o}he genau, \emph{auf das Atom} berechnen. Man kann immer nur ein Intervall betrachten, in welchem sich die stetige, reelle Zufallsvariable befindet. Denn die Wahrscheinlichkeit f\"{u}r einen exakten Wert, beispielsweise einen Meter Wasserstand, auf das Atom genau, kein Wasserstoff mehr oder weniger, ist immer gleich null. 

Daraus folgt, dass die Wahrscheinlichkeitsberechnung bei der Normalverteilung immer f\"{u}r Intervalle gilt und somit ein Integral ist. Berechnet man die Wahrscheinlichkeit, dass die normalverteilte, stetige Zufallsvariable $X$ einen Wert aus einem Intervall $]x_{0}; x_{1}[$ (oder $[x_{0};x_{1}]$) annimmt, so berechnet man das Integral der Normalverteilung in diesem Intervall. Man spricht bei der Normalverteilung also von einer \emph{Wahrscheinlichkeitsdichtefunktion}, bzw. Probability-density-function (PDF).

Eine normalverteilte Zufallsvariable $X \sim \mathcal{N}(2; 0.4)$ ist grafisch folgenderma\ss{}en dargestellt ($\mu$ bestimmt $x$-Position, $\sigma$ bestimmt Breite und H\"{o}he der Kurve):

\vspace{0.25cm}

\begin{figure}[h!]
	\begin{tikzpicture}
		\begin{axis}
		[
			x=2.4cm,
			y=2.8cm,
			xlabel=$x$,
			ylabel=$f(x)$,
			axis lines  = middle,
			domain=-1:5,
			ytick={0,0.5,...,1},
			ymax=1.2,
			samples=100,
			smooth
		]

		\addplot [ ] { 1/(0.4*sqrt(2*pi)) * e^(-0.5 * ((x-2)/0.4)^2) };

		\end{axis}
	\end{tikzpicture}
\end{figure}

\pagebreak

\sub{Standardnormalverteilung}

Eine besondere Form der Normalverteilung ist $Z \sim \mathcal{N}(0; 1)$, also jene normalverteilte Zufallsvariable $Z$ mit Erwartungswert $\mu = 0$ und Standardabweichung $\sigma = 1$. Ihre Funktion lautet: $$\phi(z) = \frac{1}{\sqrt{2\pi}} \cdot e^{-\frac{1}{2} \cdot z^2}$$ Die Verteilungsfunktion der Standardnormalverteilung ist jene Funktion $\Phi(z)$, welche f\"{u}r eine beliebige Zufallsvariable $Z \sim \mathcal{N}(0; 1)$ das Integral von $-\infty$ bis $z$ berechnet: $$\Phi(z) = \int_{-\infty}^{z} \phi(z) \, dz$$ So w\"{a}re beispielsweise $\Phi(Z\leq1) = \int_{-\infty}^{1} \phi(z) \, dz$:

\begin{figure}[h!]
	\begin{tikzpicture}[xscale=1.5, yscale=5]

		% x axis
		\draw [->] (-4, 0) -- (4, 0) node [above] {$x$};

		\foreach \x in {-4,...,4}
			\draw (\x, 0) [below] node {\x};

		% y axis
		\draw [->] (0, 0) -- (0, 0.5) node [right] {$f(x)$};

		\draw (0, 0.4) [above left] node {0.4};

		% normal distribution, colored
		\draw [red, domain=-4:1, smooth, samples=100]
			   plot (\x, {(e^(-(\x*\x)/2))/sqrt(2*pi)});

		% integral
		\foreach \z in {-2.5, -2.25, ..., 1}
			\draw [red]
			      (\z, 0)
			   -- (\z, {1/sqrt(2*pi) * e^(-(\z)^2/2)});

		% normal distribution, blank
		\draw [domain=1:4, smooth, samples=100]
			   plot (\x, {(e^(-(\x*\x)/2))/sqrt(2*pi)});

	\end{tikzpicture}
\end{figure}

M\"{o}chte man die Wahrscheinlichkeit berechnen, dass $Z$ nicht h\"{o}chstens, sondern mindestens $z$ betr\"{a}gt, also die Fl\"{a}che unter der Kurve nach $z$, von $z$ bis $+\infty$, so w\"{a}re dies entweder die Gegenwahrscheinlichkeit zu $\Phi(z)$, also $1 - \Phi(z)$, oder $\Phi(-z)$, da das Intervall \"{u}ber $z$ die selbe Fl\"{a}che hat wie das Intervall bis $-z$, also das symmetrische Gegen\"{u}ber auf der anderen Seite von $\mu$ bzw. hier der $y$-Achse. Die Wahrscheinlichkeit, dass $Z$ in einem bestimmten Intervall $]z_{1}; z_{2}[$ liegt, ist gleich dem Integral von $\phi(z)$ in den Grenzen $-\infty$ bis $z_2$, minus dem Integral von $\phi(z)$ in den Grenzen $-\infty$ bis $z_1$. Diese Differenz ist dann der Unterschied zwischen den beiden Fl\"{a}chen, somit das Intervall dazwischen. Formal gesehen: $$\Phi(z_{1} < Z < z_{2}) = \Phi(z_{2}) - \Phi(z_{1})$$  Letztlich gibt es noch die Funktion $D(z_{\varepsilon})$, welche equivalent zu $\Phi(z_{\varepsilon}) - \Phi(-z_{\varepsilon})$ ist. Sie ist also f\"{u}r symmetrische Intervalle $[\mu - \varepsilon ;  \mu + \varepsilon]$ anwendbar. $D(z_{\varepsilon})$ ist ebenso equivalent zu $2 \cdot \Phi(z_{\varepsilon}) - 1$. Der Beweis f\"{u}r den letzten Ausdruck liegt darin, dass bei einem symmetrischen Intervall mit Parameter $\varepsilon$ die untere Grenze gleich weit von $\mu$ entfernt ist wie die obere, sprich das Intervall \"{u}ber $\mu + \varepsilon$ ist das selbe wie jenes unter $\mu - \varepsilon$. Da die Wahrscheinlichkeit, dass $Z$ \"{u}ber einem bestimmten $z$ liegt, gleich $1 - \Phi(z)$, kann man diesen Ausdruck f\"{u}r die untere Grenze substituieren: $$D(z_{\varepsilon}) = \Phi(z_{\varepsilon}) - (1 - \Phi(z_{\varepsilon})) = 2 \cdot \Phi(z_{\varepsilon}) - 1$$ Es soll noch gesagt sein, dass die Wahrscheinlichkeitsintervalle der Standardnormalverteilung schon anhand ihrer grafischen Position approximiert werden k\"{o}nnen. So liegen im Intervall $]\mu - \sigma ; \mu + \sigma[$ ungef\"{a}hr $68.3 \%$ Prozent, eine Standardabweichung weiter im Intervall $]\mu - 2 \cdot \sigma ; \mu + 2 \cdot \sigma[$ schon ungef\"{a}hr $95.4 \%$ und nach drei Standardabweichungen im Intervall $]\mu - 3 \cdot \sigma ; \mu + 3 \cdot \sigma[$ schon $99.7 \%$.

\begin{figure}[ht!]
	\begin{tikzpicture}[xscale=1.5, yscale=5]

		% x axis
		\draw [->] (-4, 0) -- (4, 0) node [above] {$x$};

		\foreach \x in {-4,...,4}
			\draw (\x, 0) [below] node {\x};

		% y axis
		\draw [->] (0, 0) -- (0, 0.5) node [right] {$f(x)$};

		\draw (0, 0.4) [above left] node {0.4};

		% normal distribution
		\draw [domain=-4:4, smooth, samples=100]
			   plot (\x, {(e^(-(\x*\x)/2))/sqrt(2*pi)});

		% first interval, left border
		\draw [red]
		      (-1, 0)
		   -- (-1, 0.2419) node [pos=0.7, right]
		                   {\hspace{0.2cm}$\mu - \sigma$};

		% first interval, right border
		\draw [red] 
		      ( 1, 0)
		   -- ( 1, 0.2419) node [pos=0.7, left]
		                   {\hspace{0.1cm}$\mu + \sigma$};

		% first interval, arrows below graph
		\draw [red, <->]
		      (-1, -0.15)
		   -- ( 1, -0.15) node [midway, below] {$68.3 \%$};

		% second interval, left border
		\draw [blue]
		      (-2, 0)
		   -- (-2, 0.11) node [above]
		                   {\hspace{0.2cm}$\mu - 2 \cdot \sigma$};

		% second interval, right border
		\draw [blue] 
		      ( 2, 0)
		   -- ( 2, 0.11) node [above]
		                   {\hspace{0.1cm}$\mu + 2 \cdot \sigma$};

		% second interval, arrows below graph
		\draw [blue, <->]
		      (-2, -0.3)
		   -- ( 2, -0.3) node [midway, below] {$95.4 \%$};

		% third interval, left border
		\draw [teal]
		      (-3, 0)
		   -- (-3, 0.11) node [above]
		                   {\hspace{0.2cm}$\mu - 3 \cdot \sigma$};

		% third interval, right border
		\draw [teal] 
		      ( 3, 0)
		   -- ( 3, 0.11) node [above]
		                   {\hspace{0.1cm}$\mu + 3 \cdot \sigma$};

		% third interval, arrows below graph
		\draw [teal, <->]
		      (-3, -0.45)
		   -- ( 3, -0.45) node [midway, below] {$99.7 \%$};

	\end{tikzpicture}
\end{figure}

\pagebreak

\sub{$z$-Transformation}

Letztlich sei noch anzumerken, dass man jede nicht-standardisierte Normalverteilung zu einer standardisierten transformieren kann. Diesen Vorgang nennt man \emph{$z$-Transformation}. Dabei wird der Ausdruck $\frac{x - \mu}{\sigma}$ durch die Variable $z$ ersetzt, um somit die nicht-standardisierte Glockenkurve auf der $x$-Achse so zu verschieben, dass $\mu = 0$ und ihre Breite und H\"{o}he so anzupassen, dass $\sigma = 1$. Dies tr\"{a}gt den Vorteil, dass man nur die Werte der Standardnormalverteilung zu wissen braucht und die Zufallsvariablen aller anderen Normalverteilungen auf diese standardisierten Werte zur\"{u}ckf\"{u}hren kann. $$\frac{1}{\sigma \cdot \sqrt{2\pi}} \cdot e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}$$ $$\Downarrow$$ $$z = \frac{x - \mu}{\sigma} $$ $$\Downarrow$$ $$\frac{1}{\sqrt{2\pi}} \cdot e^{-\frac{1}{2} z^2}$$ Man \"{u}berlege sich, was die $z$-Transformation eigentlich ist, bzw. wie sie funktioniert. $x$ ist ein absoluter Wert den die stetige normalverteilte Zufallsvariable $X$ annehmen kann, beispielsweise einen IQ von 110. $\mu$ ist in diesem Fall laut Definition des Intelligenz-Quotienten gleich 100 und $\sigma$ gleich 15. Nun soll dieser normalverteilte Wert 110 mit $\mu=100$ und $\sigma=15$ so transformiert werden, dass seine Wahrscheinlichkeit mit der Standardnormalverteilung $\mathcal{N}(\mu=0;\sigma=1)$ gefunden werden kann. Die Zufallsvariable $Z$ ist hier die standardnormalverteilte Zufallsvariable, welche um $\mu=0$ links und rechts schwankt. Zun\"{a}chst muss der Wert 110 auf den Mittelwert $\mu=0$ normiert werden. Dazu subtrahiert man den alten Mittelwert $\mu=100$. Das Ergebnis lautet $x - \mu = 110 - 100 = 10$, schwankt also nun um 0 und ist daher von der Position her passend f\"{u}r die Standardnormalverteilung. Jetzt muss $x$ noch nach der Standardabweichung $\sigma = 1$ normiert werden. Es gilt folgendes Ver\"{a}ltnis: $x - \mu$ ist zur alten Standardabweichung $\sigma = 100$, so wie die $z$-transformierte Variable zur standardisierten Standardabweichung $1$: $$x - \mu : \sigma = z : 1 \Rightarrow \frac{x-\mu}{\sigma} = \frac{z}{1} \Rightarrow z = \frac{x-\mu}{\sigma}$$ Setzt man nun ein, erh\"{a}lt man den $z$-Wert: $$z = \frac{110 - 100}{115} = \frac{2}{3}$$ 

\pagebreak

\sub{$p$ bestimmen}

Um nun die Wahrscheinlichkeit $p$ eines Zufallsereignises bei einer nicht-standardisierten Normalverteilung $\mathcal{N}(\mu; \sigma)$ zu berechnen, muss man zuerst den Parameter $z$ mittels der $z$-Transformation berechnen und dann den passenden Wahrscheinlichkeitswert aus einer $\Phi$-Tabelle entnehmen.

\textbf{Beispiel}: \emph{Eine Zufallsvariable $X$ ist normalverteilt mit $X \sim \mathcal{N}(\mu=1.04; \sigma=0.02)$, berechne die Wahrscheinlichkeit dass die Zufallsvariable einen Wert zwischen $1$ und $1.1$ annimmt.}

\begin{table}[h!]
	\begin{tabular}{l l}
	I. Durchf\"{u}hrung der $z$-Transformation f\"{u}r $x_{2} = 1.1$: & $z_{2} = \frac{x_{2} - \mu}{\sigma} = \frac{1.1 - 1.04}{0.02} = 3$
	\\ & \\
	II. Durchf\"{u}hrung der $z$-Transformation f\"{u}r $x_{1} = 1$: & $z_{2} = \frac{x_{1} - \mu}{\sigma} = \frac{1 - 1.04}{0.02} = -2$
	\\ & \\
	III. Ermittlung der Wahrscheinlichkeit f\"{u}r $z_{2}$: & $\Phi(3) = 0.9987$
	\\ & \\
	IV. Ermittlung der Wahrscheinlichkeit f\"{u}r $z_{1}$: & $\Phi(-2) = 0.0228$
	\\ & \\
	V. Berechnung der Differenz und somit $p$: & $\Phi(z_{2}) - \Phi(z_{1}) = 0.9987 - 0.0228 = 97.59\%$
	\end{tabular}
\end{table}

\textbf{Weiters}: \emph{Berechne auch die Wahrscheinlichkeit, dass die Zufallsvariable einen Wert h\"{o}her als 1.02 annimmt.}

\begin{table}[h!]
	\begin{tabular}{p{10cm} l}
	I. Durchf\"{u}hrung der $z$-Transformation f\"{u}r $x = 1.02$: & $z = \frac{x - \mu}{\sigma} = \frac{1.02 - 1.04}{0.02} = -1$
	\\ & \\
	II. Da es gilt $p(X > x)$ zu ermitteln, also die Fl\"{a}che unter der Kurve zwischen $x$ und $+\infty$, muss entweder die Gegenwahrscheinlichkeit von $\Phi(z)$ berechnet, also $1 - \Phi(z)$, oder das Vorzeichen von $z$ invertiert werden: $\Phi(-z)$. &
	\\ & \\
	III. Ermittlung der Wahrscheinlichkeit f\"{u}r $z$ aus der $\Phi$-Tabelle: & $1 - \Phi(-1) = \Phi(1) = 0.8413$
	\end{tabular}
\end{table}

\textbf{Letztlich}: \emph{Berechne zus\"{a}tzlich noch die Wahrscheinlichkeit, dass die Zufallsvariable einen Wert niedriger als 1 annimmt.}

\begin{table}[h!]
	\begin{tabular}{p{10cm} l}
	I. Durchf\"{u}hrung der $z$-Transformation f\"{u}r $x = 1$: & $z = \frac{x - \mu}{\sigma} = \frac{1 - 1.04}{0.02} = -2$
	\\ & \\
	II. Da es hier gilt $p(X < x)$ zu ermitteln, also die Fl\"{a}che unter der Kurve zwischen $-\infty$ und $x$, kann man $\Phi(z)$ verwenden. &
	\\ & \\
	III. Ermittlung der Wahrscheinlichkeit f\"{u}r $z$ aus der $\Phi$-Tabelle: & $\Phi(-2) = 0.0288$
	\end{tabular}
\end{table}

Allgemein gilt also: 

\textbf{$X$ geringer als $x$}: $P(X < x) = \Phi(z) = \Phi\left(\frac{x - \mu}{\sigma}\right)$

\textbf{$X$ gr\"{o}\ss{}er als} $x$: $P(X > x) = 1 - \Phi(z) = 1 - \Phi\left(\frac{x - \mu}{\sigma}\right) = \Phi(-z) = \Phi\left[-\left(\frac{x - \mu}{\sigma}\right)\right]$

\textbf{Symmetrisches Intervall}: $P(x_{1} < X < x_{2}) = 2 \cdot \Phi(z_{2}) - 1 = 2 \cdot \Phi\left(\frac{x_{2} - \mu}{\sigma}\right) - 1$

\textbf{Asymmetrisches Intervall}: $P(x_{1}< X < x_{2}) = \Phi(z_{2}) - \Phi(z_{1}) = \Phi\left(\frac{x_{2} - \mu}{\sigma}\right) - \Phi\left(\frac{x_{1} - \mu}{\sigma}\right)$

\sub{$x$ bestimmen}

Generell erfordert es zur Berechnung des Wertes $x$ einer normalverteilten Zufallsvariable $X$ den Erwartungswert $\mu$, die Standardabweichung $\sigma$ sowie eine passende Wahrscheinlichkeit $p$, wo $p$ entweder die Wahrscheinlichkeit $P(X > x)$ oder $P(X < x)$ ist. Auch sei angemerkt, dass in diesem Fall nicht die $\Phi$-Funktion, sondern ihr Invers $\Phi^{-1}$ von Interesse ist, da man nicht $p$ f\"{u}r einen bestimmten $z$-Wert, sondern das passende $z$ f\"{u}r eine Wahrscheinlichkeit $p$ sucht. Dann gilt es, die $z$-Transformation r\"{u}ckg\"{a}ngig zu machen: $$z = \frac{x - \mu}{\sigma}$$ $$\Downarrow$$ $$x = z \cdot \sigma + \mu$$

\textbf{Beispiel}: \emph{Ermittle jenen normalverteilten Wert $x \sim \mathcal{N}(\mu = 5; \sigma = 1.5)$, welchen die Zufallsvariable X in $15\%$ aller F\"{a}lle unterschreitet.}

Berechnung von $x$ f\"{u}r $P(Z < x) = 0.15$: $x = z \cdot \sigma + \mu \Rightarrow \Phi^{-1}(0.15) \cdot 1.5 + 5 \Rightarrow -1.035 \cdot 1.5 + 5 = 3.4475$

\textbf{Beispiel}: \emph{Ermittle jenen Wert $\varepsilon$, sodass die Zufallsvariable Z zu $95\%$ im symmetrischen Intervall $] \mu - \varepsilon ; \mu + \varepsilon [$ liegt, wo $\mu = 3600$ und $\sigma = 200$.}

\begin{figure}[h!]
	\begin{tikzpicture}[xscale=1.5, yscale=5]

		% x axis
		\draw [->] (-4, 0) -- (4, 0) node [above] {$x$};

		\foreach \x in {-4,...,4}
			\draw (\x, 0) [below] node {\x};

		% y axis
		\draw [->] (0, 0) -- (0, 0.5) node [right] {$f(x)$};

		\draw (0, 0.4) [above left] node {0.4};

		% normal distribution, colored
		\draw [red, domain=-1.955:1.955, smooth, samples=100]
			   plot (\x, {(e^(-(\x*\x)/2))/sqrt(2*pi)});

		% integral
		\foreach \z in {-1.955, -1.6, ..., 1.955}
			\draw [red]
			      (\z, 0)
			   -- (\z, {1/sqrt(2*pi) * e^(-(\z)^2/2)});

		% normal distribution, blank
		\draw [domain=-4:-1.955, smooth, samples=100]
			   plot (\x, {(e^(-(\x*\x)/2))/sqrt(2*pi)});

		% normal distribution, blank
		\draw [domain=1.955:4, smooth, samples=100]
			   plot (\x, {(e^(-(\x*\x)/2))/sqrt(2*pi)});

	\end{tikzpicture}
	\caption*{Veranschaulichung}
\end{figure}

Hierbei muss man zuerst definieren, wie man $Z$ am besten berechnet. In dieser Aufgabenstellung ist im Grunde genommen nur die obere Grenze des symmetrischen Intervalls relevant. Das hei\ss{}t, man m\"{u}sste lediglich den $x$-Wert der oberen Grenze berechnen und von diesem $\mu$ subtrahieren, um somit $\varepsilon$ zu erhalten. Diesen $x$-Wert erhalten wir, in dem wir die Wahrscheinlichkeit $p$ in Anbetracht ziehen, dass $Z$ weniger als $x$ ist: $P(Z < \mu + \varepsilon)$. Diese Wahrscheinlichkeit geht jedoch von $-\infty$ bis $x$, ist also nicht $0.95$, sondern $0.95$ plus die Wahrscheinlichkeit, dass $Z$ geringer als die untere Grenze ist: $p + P(Z < \mu - \varepsilon)$. Analysiert man die Problemstellung weiter, erkennt man dass diese Wahrscheinlichkeit $P(Z < \mu - \varepsilon)$ gleich $0.5 \cdot (1 - p)$ ist. Dies folgt daraus, dass die Wahrscheinlichkeit au\ss{}erhalb des Intervalls links und rechts zusammen $1 - p$ ist, einzeln daher die H\"{a}lfte davon. Der $x$-Wert der oberen Grenze $\mu + \varepsilon$ muss also sein: 

$$x = z \cdot \sigma + \mu \Rightarrow \Phi^{-1}\left(p + \frac{1 -p}{2}\right) \cdot \sigma + \mu$$ 

\pagebreak

Weitere Beobachtungen zeigen, dass $p + \frac{1 - p}{2}$ gleich $\frac{1 + p}{2}$ ist. Ebenso ist hier anzumerken, dass die Formel oben dazu dient, den $x$-Wert der oberen Grenze zu berechnen. Die Aufgabenstellung verlangt jedoch $\varepsilon$, den Abstand dieses $x$-Wertes der oberen Grenze vom Erwartungswert $\mu$. Es sollte also eigentlich hei\ss{}en: $$\varepsilon = \Phi\left(\frac{1 + p}{2}\right) \cdot \sigma + \mu - \mu$$ Dies kann nun endg\"{u}ltig auf diesen Ausdruck gek\"{u}rzt werden: $$\varepsilon = \Phi^{-1}\left(\frac{1 + p}{2}\right) \cdot \sigma$$

Allgemein gilt f\"{u}r die Bestimmung von $x$ also:

\textbf{$p$ f\"{u}r $P(Z < X)$}: $X = \Phi^{-1}(p) \cdot \sigma + \mu$

\textbf{$p$ f\"{u}r $P(Z > X)$}: $X = -\Phi^{-1}(p) \cdot \sigma + \mu = \Phi^{-1}(1 - p) \cdot \sigma + \mu$

\textbf{Symmetrisches Intervall}: $\varepsilon = \Phi^{-1}\left(\frac{1 + p}{2}\right) \cdot \sigma = D^-1(p) \cdot \sigma$

\sub{$\mu$ bestimmen}

Oftmals ist nur die Standardabweichung $\sigma$ gegeben, ein Wert $x$ der Zufallsvariable $X$ sowie die Wahrscheinlichkeit dass $p$ dass $X$ gr\"{o}\ss{}er oder kleiner als dieses $x$ ist. Die Aufgabe besteht dann darin, $\mu$ zu bestimmen. Wiedermals wird diese Aufgabe durch eine Umformung der $z$-Transformationsformel gel\"{o}st: $$z = \frac{x - \mu}{\sigma}$$ $$\Downarrow$$ $$\mu = -z \cdot \sigma + x = -\Phi^{-1}(p) \cdot \sigma + x$$

\textbf{Beispiel}: \emph{Bestimme den Erwartungswert $\mu$ so, dass bei einer Standardabweichung $\sigma = 2$ die normalverteilte Zufallsvariable $X$ zu $95 \%$ einen Wert h\"{o}her als 495 annimmt.}

Bei der Berechnung von $\mu$ muss man hier darauf achten, dass $p = P(Z > X)$. Das hei\ss{}t, dass der $z$ Wert entweder f\"{u}r die Gegenwahrscheinlichkeit $1 - p$ berechnet werden oder sein Vorzeichen ver\"{a}ndert werden muss: $$P(Z > X) \Rightarrow \Phi^{-1}(1 - p) = -\Phi^{-1}(p)$$ $\mu$ wird dann so bestimmt: $$\mu = -z \cdot \sigma + x = -[-\Phi^{-1}(p)] \cdot \sigma + x = 1.645 \cdot 2 + 495 = 498.3$$ Allgemein:

\textbf{Wenn $p$ f\"{u}r $P(X < x)$:} $\mu = -z \cdot \sigma + x = -\Phi^{-1}(p) \cdot \sigma + x$

\textbf{Wenn $p$ f\"{u}r $P(X > x)$:} $\mu = -z \cdot \sigma + x = -[-\Phi^{-1}(p)] \cdot \sigma + x = \Phi^{-1}(p) \cdot \sigma + x$

\pagebreak

\sub{$\sigma$ bestimmen}

Zur Berechnung der Standardabweichung $\sigma$ geht man \"{a}hnlich vor wie bei jener des Erwartungswertes: $$z = \frac{x - \mu}{\sigma}$$ $$\Downarrow$$ $$ \sigma = \frac{x - \mu}{z} = \frac{x - \mu}{\Phi^{-1}(p)}$$

\textbf{Beispiel}: \emph{Ermittle die Standardabweichung $\sigma$ so, dass es ein symmetrisches Intervall $]\mu - \varepsilon ; \mu + \varepsilon[$ mit $\varepsilon = 1$ geben kann, in welchem sich die Zufallsvariable $X$ zu $95 \%$ befindet.}

Hierzu sollte klargestellt werden, dass der Ausdruck $x - \mu$ bei der $z$-Transformation den Abstand zwischen $x$ und $\mu$ berechnet. Wir wissen hier, dass dieser symmetrische Abstand $\varepsilon$ den Wert 1 hat, k\"{o}nnen $x-\mu$ also durch 1 ersetzen. Da es sich um ein symmetrisches Intervall handelt, k\"{o}nnen wir nicht direkt $p$ verwenden, sondern m\"{u}ssen wie bei der Berechnung symmetrischer Intervalle die Wahrscheinlichkeit, dass $Z$ geringer als die untere Intervallgrenze ist, zu $p$ hinzuf\"{u}gen. Generell hilft uns hier die vorhin definierte Formel zur Berechnung eines symmetrischen Intervalls: $$\varepsilon = \Phi^{-1}\left(\frac{1 + p}{2}\right) \cdot \sigma$$ $$\Downarrow$$ $$\sigma = \frac{\varepsilon}{\Phi^{-1}\left(\frac{1 + p}{2}\right)} = \frac{1}{\Phi^{-1}(0.975)} = \frac{1}{1.955}$$ $$\Downarrow$$ $$\sigma = 0.51$$

Allgemein:

\textbf{Wenn $p$ f\"{u}r $P(Z < X)$:} $\sigma = \frac{x - \mu}{\Phi^{-1}(p)}$

\textbf{Wenn $p$ f\"{u}r $P(Z > X)$:} $\sigma = \frac{x - \mu}{\Phi^{-1}(1 - p)} = \frac{x - \mu}{-\Phi^{-1}(p)}$

\textbf{Symmetrisches Intervall}: $\sigma = \frac{\varepsilon}{\Phi^{-1}\left(\frac{1 + p}{2}\right)} = \frac{\varepsilon}{D^-1(z)}$

\end{document}